{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4e216f93ee6bf77b957ab02d368f73b",
     "grade": false,
     "grade_id": "cell-52506fc51faeb1a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# HW3 Convolutional Neural Network\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this homework, you will get introduced to CNN. More specifically, you will try CNN on X-Ray images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:40.758824Z",
     "start_time": "2022-02-24T23:56:40.111148Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "136fc4b046635d06cfa3a569a3ecf59c",
     "grade": false,
     "grade_id": "cell-83a510935b5eb408",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# record start time\n",
    "_START_RUNTIME = time.time()\n",
    "\n",
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "# Define data and weight path\n",
    "DATA_PATH = \"../HW3_CNN-lib/data\"\n",
    "WEIGHT_PATH = \"../HW3_CNN-lib/resnet18_weights_9.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdd8366623622a245451a980fa458b13",
     "grade": false,
     "grade_id": "cell-f24c5a8a552afa64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## About Raw Data\n",
    "\n",
    "Pneumonia is a lung disease characterized by inflammation of the airspaces in the lungs, most commonly due to an infection. In this section, you will train a CNN model to classify Pneumonia disease (Pneumonia/Normal) based on chest X-Ray images. \n",
    "\n",
    "The chest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old. All chest X-ray imaging was performed as part of patientsâ€™ routine clinical care. You can refer to this [link](https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "349700e55d0cb2d500bd7ee612ce7451",
     "grade": false,
     "grade_id": "cell-115765ba096f745e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1 Load and Visualize the Data [20 points]\n",
    "\n",
    "The data is under `DATA_PATH`. In this part, you are required to load the data into the data loader, and calculate some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:40.767090Z",
     "start_time": "2022-02-24T23:56:40.761140Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#input\n",
    "# folder: str, 'train', 'val', or 'test'\n",
    "#output\n",
    "# number_normal: number of normal samples in the given folder\n",
    "# number_pneumonia: number of pneumonia samples in the given folder\n",
    "def get_count_metrics(folder, data_path=DATA_PATH):\n",
    "    \n",
    "    '''\n",
    "    TODO: Implement this function to return the number of normal and pneumonia samples.\n",
    "          Hint: !ls $DATA_PATH\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    number_normal = 0\n",
    "    number_pneumonia = 0\n",
    "    \n",
    "    number_pneumonia = len(os.listdir(f\"{data_path}/{folder}/PNEUMONIA\"))\n",
    "    number_normal = len(os.listdir(f\"{data_path}/{folder}/NORMAL\"))\n",
    "\n",
    "    return number_normal, number_pneumonia\n",
    "\n",
    "\n",
    "#output\n",
    "# train_loader: train data loader (type: torch.utils.data.DataLoader)\n",
    "# val_loader: val data loader (type: torch.utils.data.DataLoader)\n",
    "def load_data(data_path=DATA_PATH):\n",
    "    \n",
    "    '''\n",
    "    TODO: Implement this function to return the data loader for \n",
    "    train and validation dataset. Set batchsize to 32.\n",
    "    \n",
    "    You should add the following transforms (https://pytorch.org/vision/stable/transforms.html):\n",
    "        1. transforms.RandomResizedCrop: the images should be cropped to 224 x 224\n",
    "        2. transforms.ToTensor: just to convert data/labels to tensors\n",
    "    You should set the *shuffle* flag for *train_loader* to be True, and False for *val_loader*.\n",
    "    \n",
    "    HINT: Consider using `torchvision.datasets.ImageFolder`.\n",
    "    '''\n",
    "\n",
    "    import torchvision\n",
    "    import torchvision.datasets as datasets\n",
    "    import torchvision.transforms as transforms\n",
    "\n",
    "    # your code here\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop((224, 224)),\n",
    "        transforms.ToTensor()]\n",
    "    )\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        root=f\"{data_path}/train\",\n",
    "        transform=transform\n",
    "    )\n",
    "    # validation dataset\n",
    "    valid_dataset = datasets.ImageFolder(\n",
    "        root=f\"{data_path}/val\",\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=32, shuffle=True\n",
    "    )\n",
    "    # validation data loaders\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=32, shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:40.782719Z",
     "start_time": "2022-02-24T23:56:40.768362Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15f535a0ae204e5aad2281b5a6f08904",
     "grade": true,
     "grade_id": "cell-458b2462e7d5c860",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert type(get_count_metrics('train')) is tuple\n",
    "assert type(get_count_metrics('val')) is tuple\n",
    "\n",
    "assert get_count_metrics('train') == (335, 387)\n",
    "assert get_count_metrics('val') == (64, 87)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:41.043247Z",
     "start_time": "2022-02-24T23:56:40.785305Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0eaefe684b79079399e71b299b2e9ffe",
     "grade": true,
     "grade_id": "cell-0be378369cbc90a4",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "train_loader, val_loader = load_data()\n",
    "\n",
    "assert type(train_loader) is torch.utils.data.dataloader.DataLoader\n",
    "\n",
    "assert len(train_loader) == 23\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:42.904466Z",
     "start_time": "2022-02-24T23:56:41.045284Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0f01779427aed1508bf70e4f933cd99",
     "grade": false,
     "grade_id": "cell-e908531cdc33dff4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS PART\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img, title):\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def show_batch_images(dataloader, k=8):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images = images[:k]\n",
    "    labels = labels[:k]\n",
    "    img = torchvision.utils.make_grid(images, padding=25)\n",
    "    imshow(img, title=[\"NORMAL\" if x==0  else \"PNEUMONIA\" for x in labels])\n",
    "\n",
    "train_loader, val_loader = load_data()   \n",
    "for i in range(2):\n",
    "    show_batch_images(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f52a2ed6e02075d8c208461e4ff5b18",
     "grade": false,
     "grade_id": "cell-9739d5ae7e1cafc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2 Build the Model [35 points]\n",
    "\n",
    "This time, you will define a CNN architecture. Instead of an MLP, which used linear, fully-connected layers, you will use the following:\n",
    "- [Convolutional layers](https://pytorch.org/docs/stable/nn.html#conv2d), which can be thought of as stack of filtered images.\n",
    "- [Maxpooling layers](https://pytorch.org/docs/stable/nn.html#maxpool2d), which reduce the x-y size of an input, keeping only the most active pixels from the previous layer.\n",
    "- The usual Linear + Dropout layers to avoid overfitting and produce a 2-dim output.\n",
    "\n",
    "Below is a typical CNN architicture which consists of \\[INPUT - CONV - RELU - POOL - FC\\] layers.\n",
    "\n",
    "<img src=./img/convnet.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cab339c9d8cfeb03abfe901560e1da07",
     "grade": false,
     "grade_id": "cell-7fa15685c339c1c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1 Convolutional Layer Output Volume [10 points]\n",
    "Before we get started, let us do a warm-up question.\n",
    "\n",
    "Calculate the output volume for a convolutional layer: given the input volume size $W$, the kernel/filter size $F$, the stride $S$, and the amount of zero padding $P$ used on the border, calculate the output volume size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:42.908664Z",
     "start_time": "2022-02-24T23:56:42.905655Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def conv_output_volume(W, F, S, P):\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: Given the input volume size $W$, the kernel/filter size $F$, \n",
    "    the stride $S$, and the amount of zero padding $P$ used on the border, \n",
    "    calculate the output volume size.\n",
    "    Note the output should a integer. \n",
    "    \"\"\"\n",
    "    \n",
    "    # your code here\n",
    "    return np.floor((W + 2*P - F)/S) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:42.914951Z",
     "start_time": "2022-02-24T23:56:42.910005Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e142c96f145ec1e54383c700217e76ca",
     "grade": true,
     "grade_id": "cell-00dd6923b07cc0c6",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert conv_output_volume(W=7, F=3, S=1, P=0) == 5\n",
    "assert conv_output_volume(W=7, F=3, S=2, P=0) == 3\n",
    "assert conv_output_volume(W=8, F=3, S=2, P=0) == 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d81a0491741ab4ef320c2433ef40752",
     "grade": false,
     "grade_id": "cell-cdc8af08d2459036",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 Define CNN [15 points]\n",
    "Now, define your own CNN model below. Note that, the more convolutional layers you include, the more complex patterns the model can detect. For now, it is suggested that your final model include 2 or 3 convolutional layers as well as linear layers + dropout in between to avoid overfitting.\n",
    "\n",
    "It is also a good practice to look at existing research and implementations of related models as a starting point for defining your own models. You may find it useful to look at this [PyTorch classification example](https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/cifar10_tutorial.py).\n",
    "\n",
    "Please do not use the same model structure as in Section 2.3. Specifically, let's define a small model with less than 10 layers/modules (must be fewer than 20). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:42.922935Z",
     "start_time": "2022-02-24T23:56:42.916267Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # your code here\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(in_features=128 * 28 * 28, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=2)\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #input is of shape (batch_size=32, 3, 224, 224) if you did the dataloader right\n",
    "        # your code here\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.view(-1, 128 * 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:42.938549Z",
     "start_time": "2022-02-24T23:56:42.924284Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80f07ddd1b593beaa7f709ddbc5e7921",
     "grade": false,
     "grade_id": "cell-01c27cfe7bb587a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "simple_model = SimpleCNN()\n",
    "simple_model_size = sum([param.nelement() * param.element_size() for param in simple_model.parameters()]) / 1e9\n",
    "print('SimpleCNN size in GB:', simple_model_size)\n",
    "assert simple_model_size <= 1, 'SimpleCNN is too large! Please minimize the number of parameters.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:43.237817Z",
     "start_time": "2022-02-24T23:56:42.942900Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62a7e757dfdfceb2668e0e515b75b959",
     "grade": true,
     "grade_id": "cell-0912d310421bd203",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "simple_model = SimpleCNN()\n",
    "\n",
    "assert issubclass(type(simple_model), nn.Module), \"Your CNN model should be a torch.nn.Module instance.\"\n",
    "assert len(list(simple_model.modules())) < 20, \"Your CNN model is too big. Please re-design.\"\n",
    "\n",
    "test_input = torch.zeros(32, 3, 224, 224)\n",
    "test_output = simple_model(test_input)\n",
    "assert test_output.shape == torch.Size([32,2]), \"Your CNN model has a wrong output size.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60c30d5f3a54bebccd80d4725b89a4d3",
     "grade": false,
     "grade_id": "cell-10d68ed45ec4c640",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.3 Using Predefined CNN Model [10 points]\n",
    "In this section, we will import a predefined CNN, the ResNet18 model, which is pretty successful in many image classification tasks. We will modify the last layer to use it on our binary classification problem, but keep the rest of the structure the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:43.243099Z",
     "start_time": "2022-02-24T23:56:43.239393Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#output\n",
    "# model: the cnn model\n",
    "def get_cnn_model():\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: Define the CNN model here. \n",
    "        We will use a ResNet18 model. \n",
    "        For now, please set `pretrained=False`. We will manually load the weights later.\n",
    "        Then, replace the last layer (model.fc) with a nn.Linear layer\n",
    "            The new model.fc should have the same input size but a new output_size of 2\n",
    "    \"\"\"\n",
    "    \n",
    "    from torchvision import models\n",
    "    \n",
    "    num_classes = 2\n",
    "    # your code here\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "    #For computation efficiency, we will freeze the weights in the bottom layers\n",
    "    for param in model.named_parameters():\n",
    "        if param[0].split(\".\")[0] == 'fc':\n",
    "            continue\n",
    "        param[1].requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:43.614047Z",
     "start_time": "2022-02-24T23:56:43.244660Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02de22ac8bf7e829ea7f99221122b0fa",
     "grade": true,
     "grade_id": "cell-5dc1c89e9698d0d8",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert issubclass(type(get_cnn_model()), nn.Module), \"Your CNN model should be a torch.nn.Module instance\"\n",
    "model = get_cnn_model()\n",
    "assert len(list(model.modules())) == 68, \"# of modules mismtach - Please use ResNet18\"\n",
    "assert len(list(model.parameters())) == 62, \"# of parameter tensors mismtach - different model. Please use ResNet18\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bce659dde8cd0c6a9c6b9671dc36607c",
     "grade": false,
     "grade_id": "cell-3b34f300dcde3d1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3 Training the Network [25 points]\n",
    "\n",
    "Due to the computation environment constraint, we will load some pre-trained weights instead of training everything from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:43.779306Z",
     "start_time": "2022-02-24T23:56:43.615829Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5aa86039e33d49c1bb3473d2552cd395",
     "grade": false,
     "grade_id": "cell-51d29fbc3eaa9c24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = get_cnn_model()\n",
    "#Load the pretrained weights\n",
    "#If it fails, it probably means you did not define the model correctly\n",
    "model.load_state_dict(torch.load(WEIGHT_PATH, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2060707a8cce5ba7b696eb8451da7984",
     "grade": false,
     "grade_id": "cell-8d597f91c30006e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.1 Criterion and Opimizer [10 points]\n",
    "In this part, you will define the loss and optimizer for the model and then perform model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:43.784995Z",
     "start_time": "2022-02-24T23:56:43.781190Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Specify loss function (CrossEntropyLoss) and assign it to `criterion`.\n",
    "Spcify optimizer (SGD) and assign it to `optimizer`.\n",
    "Hint: the learning rate is usually a small number on the scale of 1e-4 ~ 1e-2\n",
    "\"\"\"\n",
    "\n",
    "criterion = None\n",
    "optimizer = None\n",
    "\n",
    "# your code here\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:43.790542Z",
     "start_time": "2022-02-24T23:56:43.786517Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "354d65bbf85b7591848b860cb439b07e",
     "grade": true,
     "grade_id": "cell-40bee829e3b63b7d",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert isinstance(criterion, torch.nn.modules.loss.CrossEntropyLoss)\n",
    "assert isinstance(optimizer, torch.optim.SGD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cecc2bb0b9e611404f60a51196d2da02",
     "grade": false,
     "grade_id": "cell-a4726bc7890c2ffa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.2 Training [15 points]\n",
    "\n",
    "Now let us train the CNN model we previously created.\n",
    "\n",
    "Remember that from the previous HW, to train the model, you should follow the following step:\n",
    "- Clear the gradients of all optimized variables\n",
    "- Forward pass: compute predicted outputs by passing inputs to the model\n",
    "- Calculate the loss\n",
    "- Backward pass: compute gradient of the loss with respect to model parameters\n",
    "- Perform a single optimization step (parameter update)\n",
    "- Update average training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:56:43.797349Z",
     "start_time": "2022-02-24T23:56:43.792336Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# number of epochs to train the model\n",
    "# make sure your model finish training within 4 minutes on a CPU machine\n",
    "# You can experiment different numbers for n_epochs, but even 1 epoch should be good enough.\n",
    "n_epochs = 1\n",
    "\n",
    "def train_model(model, train_dataloader, n_epoch=n_epochs, optimizer=optimizer, criterion=criterion):\n",
    "    import torch.optim as optim\n",
    "    \"\"\"\n",
    "    :param model: A CNN model\n",
    "    :param train_dataloader: the DataLoader of the training data\n",
    "    :param n_epoch: number of epochs to train\n",
    "    :return:\n",
    "        model: trained model\n",
    "    \"\"\"\n",
    "    model.train() # prep model for training\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        curr_epoch_loss = []\n",
    "        for data, target in tqdm(train_dataloader):\n",
    "            \"\"\"\n",
    "            TODO: Within the loop, do the normal training procedures:\n",
    "                   pass the input through the model\n",
    "                   pass the output through loss_func to compute the loss (name the variable as *loss*)\n",
    "                   zero out currently accumulated gradient, use loss.basckward to backprop the gradients, then call optimizer.step\n",
    "            \"\"\"\n",
    "            # your code here\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "            \n",
    "            curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "        print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:57:35.260474Z",
     "start_time": "2022-02-24T23:56:43.798978Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "707b88d0c6894da95c20917eb50f73e7",
     "grade": false,
     "grade_id": "cell-79f9007519fee573",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# get train and val data loader\n",
    "train_loader, val_loader = load_data()\n",
    "\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model = train_model(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:57:39.942242Z",
     "start_time": "2022-02-24T23:57:35.262531Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de74ad731922c0017aecf3f788c6257f",
     "grade": true,
     "grade_id": "cell-8bf229ea988a6488",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67627ee32ae21125f8e26815364b312c",
     "grade": false,
     "grade_id": "cell-c8836a08154e7f31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4 Test the Trained Network [20 points]\n",
    "\n",
    "In this step, you will test your model on the validation data and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:57:39.947608Z",
     "start_time": "2022-02-24T23:57:39.943409Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    :return:\n",
    "        Y_pred: prediction of model on the dataloder. Should be an numpy array of ints\n",
    "        Y_true: truth labels. Should be an numpy array of ints\n",
    "    TODO:\n",
    "        evaluate the model using on the data in the dataloder.\n",
    "        Add all the prediction and truth to the corresponding list\n",
    "        Convert Y_pred and Y_true to numpy arrays (of shape (n_data_points,))\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    Y_pred = []\n",
    "    Y_true = []\n",
    "    for data, target in dataloader:\n",
    "        # your code here\n",
    "        output = model(data)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        Y_pred.append(pred.numpy())\n",
    "        Y_true.append(target.numpy())\n",
    "        \n",
    "    Y_pred = np.concatenate(Y_pred, axis=0)\n",
    "    Y_true = np.concatenate(Y_true, axis=0)\n",
    "\n",
    "    return Y_pred, Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:58:21.576080Z",
     "start_time": "2022-02-24T23:57:39.949625Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c2cd131fd20aa01ba92f64662a90e40",
     "grade": true,
     "grade_id": "cell-c74a407692de012e",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred, y_true = eval_model(model, val_loader)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print((\"Validation Accuracy: \" + str(acc)))\n",
    "assert acc > 0.7, \"Validation Accuracy below 0.7 for validation data!\"\n",
    "assert len(y_true) == len(y_pred) == 151, \"Output size is wrong\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T23:58:21.581466Z",
     "start_time": "2022-02-24T23:58:21.577591Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e75de0cb203a9e97517e47d62a92f95",
     "grade": false,
     "grade_id": "cell-5cf7218279fa399f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#As noted before, please make sure the whole notebook does not exceed 4 mins on a CPU\n",
    "print(\"Total running time = {:.2f} seconds\".format(time.time() - _START_RUNTIME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "illinois_payload": {
   "b64z": "",
   "nb_path": "release/HW3_CNN/HW3_CNN.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (Threads: 2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.1875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
